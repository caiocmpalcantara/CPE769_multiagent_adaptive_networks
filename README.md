# Multi-Agent Adaptive Networks Framework âœ¨

> **Distributed intelligence meets adaptive filtering** - A comprehensive MATLAB framework for cooperative multi-agent systems with advanced adaptive filtering capabilities.

## ðŸŽ¯ Project Showcase

**Innovation Hook**: *Revolutionizing distributed signal processing through intelligent agent cooperation and state-of-the-art adaptive filtering algorithms.*

### Main Goals
- **ðŸ¤ Cooperative Learning**: Enable multiple agents to collaboratively estimate unknown parameters through sophisticated information fusion strategies
- **ðŸ”„ Adaptive Filtering Excellence**: Implement and compare industry-standard algorithms (LMS, RLS, Wiener, Kalman) in distributed environments
- **ðŸ“Š Performance Analysis**: Provide comprehensive Monte Carlo simulation framework for algorithm evaluation and comparison
- **ðŸŒ Network Topology Flexibility**: Support various agent network configurations and cooperation strategies
- **ðŸŽ›ï¸ Real-time Adaptation**: Handle dynamic environments with time-varying parameters and noise characteristics

### Target Users & Use Cases
- **Researchers** in distributed signal processing and multi-agent systems
- **Engineers** developing sensor networks and cooperative estimation systems
- **Students** learning adaptive filtering and distributed algorithms
- **Applications**: Sensor fusion, distributed tracking, cooperative spectrum sensing, smart grid monitoring

---

## ðŸ“š Theoretical Foundation

### Key Theories Applied
- **Adaptive Filtering Theory**: Implements LMS, RLS, and Wiener filtering for optimal parameter estimation
- **Kalman Filtering**: State-space estimation with linear and nonlinear observation models
- **Consensus Theory**: Distributed averaging and agreement protocols for multi-agent coordination
- **Graph Theory**: Network topology representation through adjacency matrices and social learning
- **Stochastic Approximation**: Convergence analysis for distributed adaptive algorithms

### Explicit Assumptions
- **Gaussian Noise Model**: Assumes additive white Gaussian noise in sensor observations
- **Linear System Dynamics**: State transition and observation models are linear (extensible to nonlinear)
- **Connected Network Topology**: Agents form a connected graph for information exchange
- **Synchronous Updates**: All agents update simultaneously in discrete time steps
- **Stationary Statistics**: Assumes locally stationary signal statistics for adaptive convergence

---

## ðŸ—ï¸ Architectural Blueprint

### Software Architecture
**Layered Architecture** with **Strategy Pattern Integration** - *Promotes modularity and algorithm interchangeability while maintaining clear separation of concerns.*

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Application Layer                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Test Scripts  â”‚  â”‚   Simulations   â”‚  â”‚  Utilities   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     Agent Layer                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚     Agent       â”‚  â”‚  Agent_vector   â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                  Cooperation Layer                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Single_task  â”‚ â”‚ Consensus    â”‚ â”‚ Non_cooperative     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 Algorithm Layer                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   LMS   â”‚ â”‚   RLS   â”‚ â”‚ Wiener  â”‚ â”‚     Kalman      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

*Recommend creating detailed component diagrams with Mermaid.js*

---

## ðŸ” Code Anatomy

### Class Hierarchy
```plaintext
Core/
â”œâ”€ Agent/
â”‚  â”œâ”€ Agent.m (Individual learning agent)
â”‚  â”œâ”€ Agent_vector.m (Multi-agent coordinator)
â”‚  â””â”€ Cooperation_type.m (Enumeration of cooperation strategies)
â”œâ”€ Technique/
â”‚  â”œâ”€ Agent_technique.m (Abstract base for adaptive algorithms)
â”‚  â”œâ”€ Lms.m (Least Mean Squares implementation)
â”‚  â”œâ”€ Rls.m (Recursive Least Squares implementation)
â”‚  â”œâ”€ Wiener.m (Wiener filtering implementation)
â”‚  â”œâ”€ Kalman.m (Kalman filter implementation)
â”‚  â””â”€ Fusion_technique.m (Abstract base for cooperation strategies)
â”œâ”€ Simulation/
â”‚  â”œâ”€ Simulation.m (Abstract simulation framework)
â”‚  â”œâ”€ Static_sim.m (Stationary environment simulation)
â”‚  â””â”€ Noise.m (Noise generation utilities)
â””â”€ Utils/
   â”œâ”€ GeoPoint.m (Geometric coordinate utilities)
   â”œâ”€ Measure.m (Measurement processing)
   â””â”€ Noise_Model.m (Advanced noise modeling)
```

### Critical Classes

**`Agent`**: *Core learning entity that maintains state buffers and applies adaptive filtering techniques*
- Manages observation and state buffers with configurable window sizes
- Implements both self-learning (individual adaptation) and social learning (cooperation) steps
- Provides unified interface for different adaptive filtering algorithms

**`Agent_vector`**: *Multi-agent system coordinator that orchestrates cooperation strategies*
- Manages collections of agents and their network topology (B-matrix)
- Implements different cooperation types through strategy pattern
- Coordinates synchronous updates across all agents in the network

**`Agent_technique`**: *Abstract base class defining the adaptive filtering interface*
- Standardizes the `apply()` method for all filtering algorithms
- Ensures consistent parameter estimation and weight update mechanisms
- Enables seamless algorithm switching through polymorphism

**`Fusion_technique`**: *Abstract framework for inter-agent information sharing strategies*
- Defines cooperation protocols for distributed learning
- Implements social matrix normalization for weighted information fusion
- Supports various network topologies and communication constraints

**`Wiener`**: *Optimal linear filter implementation using expectation approximation*
- Estimates autocorrelation matrix R and cross-correlation vector p from data windows
- Implements gradient descent optimization with regularization
- Provides theoretical performance bounds for comparison with adaptive algorithms

---

## ðŸŽ¨ Design Patterns Catalog

### Patterns Used
- **ðŸ­ Strategy Pattern**: Interchangeable adaptive filtering algorithms (`Lms`, `Rls`, `Wiener`, `Kalman`) implement common `Agent_technique` interface
- **ðŸ—ï¸ Template Method Pattern**: Abstract base classes define algorithmic structure while allowing customization in derived classes
- **ðŸ”§ Factory Method Pattern**: `Agent_vector` creates appropriate fusion techniques based on cooperation type enumeration
- **ðŸ‘ï¸ Observer Pattern**: Agents observe neighbor updates and react through social learning mechanisms
- **ðŸŽ¯ Command Pattern**: Encapsulated update operations enable undo/redo functionality and batch processing

### Pattern â†’ File Mapping
```plaintext
Strategy Pattern:
â”œâ”€ Technique/Agent_technique.m â†’ Abstract strategy interface
â”œâ”€ Technique/Lms.m â†’ Concrete LMS strategy
â”œâ”€ Technique/Rls.m â†’ Concrete RLS strategy
â”œâ”€ Technique/Wiener.m â†’ Concrete Wiener strategy
â””â”€ Technique/Kalman.m â†’ Concrete Kalman strategy

Template Method Pattern:
â”œâ”€ Technique/Fusion_technique.m â†’ Abstract cooperation template
â”œâ”€ Technique/Single_task.m â†’ Weighted neighbor averaging
â”œâ”€ Technique/Consensus_constrain.m â†’ Global consensus implementation
â””â”€ Technique/Non_cooperative.m â†’ No information sharing

Factory Method Pattern:
â””â”€ Agent/Agent_vector.m â†’ Creates fusion techniques based on cooperation type

Observer Pattern:
â”œâ”€ Agent/Agent.m â†’ Observable agent state updates
â””â”€ Technique/Single_task.m â†’ Observer of neighbor agent states
```

---

## ðŸ“Š Diagrams & Visuals

### Recommended Visualizations
- `![Class Diagram](diagrams/class_overview.png)` â† **RECOMMENDED**: UML class relationships and inheritance hierarchy
- `![Architecture Diagram](diagrams/layered_architecture.svg)` â† **RECOMMENDED**: System architecture with data flow
- `![Cooperation Strategies](diagrams/cooperation_comparison.png)` â† **RECOMMENDED**: Visual comparison of different cooperation types
- `![Algorithm Performance](diagrams/rmse_comparison.png)` â† **RECOMMENDED**: Monte Carlo performance analysis results

### Mermaid.js Integration Examples
```mermaid
graph TD
    A[Agent_vector] --> B[Agent 1]
    A --> C[Agent 2]
    A --> D[Agent N]
    B --> E[LMS/RLS/Wiener/Kalman]
    C --> F[LMS/RLS/Wiener/Kalman]
    D --> G[LMS/RLS/Wiener/Kalman]
    A --> H[Fusion_technique]
    H --> I[Single_task]
    H --> J[Consensus_constrain]
    H --> K[Non_cooperative]
```

---

## ðŸš€ Algorithm Implementations

### Adaptive Filtering Techniques

**Least Mean Squares (LMS)**
- **Parameters**: Step size `Î¼`, regularization `Îµ`
- **Update Rule**: `H(n+1) = H(n) + Î¼Â·e(n)Â·x(n)`
- **Advantages**: Simple, robust, low computational complexity
- **Use Cases**: Real-time applications, non-stationary environments

**Recursive Least Squares (RLS)**
- **Parameters**: Forgetting factor `Î»`, initialization `Î´`
- **Update Rule**: Recursive covariance matrix inversion with exponential weighting
- **Advantages**: Fast convergence, excellent tracking capability
- **Use Cases**: High SNR scenarios, rapidly changing parameters

**Wiener Filtering**
- **Parameters**: Window size `n_win`, step size `Î¼`, regularization `Îµ`
- **Update Rule**: `H = H - 2Î¼(HÂ·R - p + ÎµÂ·H)` using estimated statistics
- **Advantages**: Optimal linear filter, theoretical performance bounds
- **Use Cases**: Stationary environments, benchmark comparisons

**Kalman Filtering**
- **Parameters**: Process noise `Q`, measurement noise `R`, initial covariance `Pâ‚€`
- **Update Rule**: Recursive Bayesian estimation with prediction and correction steps
- **Advantages**: Optimal for linear Gaussian systems, handles dynamics
- **Use Cases**: State estimation, tracking applications, sensor fusion

### Cooperation Strategies

**Non-Cooperative**: `Cooperation_type.non_cooperative`
- Agents operate independently without information sharing
- Baseline performance for comparison with cooperative methods

**Consensus Constrain**: `Cooperation_type.consensus_constrain`
- Global averaging of all agent estimates: `H_avg = mean(H_all_agents)`
- Fastest convergence but requires full network connectivity

**Single Task**: `Cooperation_type.single_task`
- Weighted combination based on network topology (B-matrix)
- Balances performance and communication requirements
- Most practical for real-world deployments

**Multi Task**: `Cooperation_type.multi_task` *(Under Development)*
- Specialized cooperation for heterogeneous agent objectives
- Future extension for complex multi-objective scenarios

---

## ðŸ§ª Getting Started

### Quick Setup
```matlab
% Add paths and initialize
addpath('./Agent/', './Technique/', './Simulation/', './Utils/');

% Create multi-agent system with LMS and single-task cooperation
agents = Agent_vector('n_agents', 6, 'coop_type', Cooperation_type.single_task);

% Run simulation
for n = 1:N_samples
    agents.update(observations(:,n), true_state);
end
```

### Performance Comparison Example
```matlab
% Compare different algorithms and cooperation strategies
test_MAS_mc;  % Monte Carlo comparison script
test_MAS_sim; % Dynamic environment simulation
```

---

**ðŸŽ“ Academic Foundation**: Based on adaptive filtering theory from Sayed's "Adaptive Filters" and Diniz's "Adaptive Filtering Algorithms and Practical Implementation" and distributed consensus protocols from multi-agent systems literature.

**ðŸ“ˆ Performance Insights**: Extensive Monte Carlo simulations demonstrate that cooperative strategies (especially single-task with RLS) achieve significantly lower RMSE compared to non-cooperative approaches, with consensus constrain providing the fastest convergence in fully connected networks.
